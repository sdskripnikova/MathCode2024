{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "572b597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nose\n",
    "from nose.tools import assert_almost_equal, ok_, eq_\n",
    "from nose.plugins.attrib import attr\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "import scipy.optimize\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import optimization\n",
    "import oracles\n",
    "\n",
    "\n",
    "def test_python3():\n",
    "    ok_(sys.version_info > (3, 0))\n",
    "\n",
    "\n",
    "def test_QuadraticOracle():\n",
    "    # Quadratic function:\n",
    "    #   f(x) = 1/2 x^T x - [1, 2, 3]^T x\n",
    "    A = np.eye(3)\n",
    "    b = np.array([1, 2, 3])\n",
    "    quadratic = oracles.QuadraticOracle(A, b)\n",
    "\n",
    "    # Check at point x = [0, 0, 0]\n",
    "    x = np.zeros(3)\n",
    "    assert_almost_equal(quadratic.func(x), 0.0)\n",
    "    ok_(np.allclose(quadratic.grad(x), -b))\n",
    "    ok_(np.allclose(quadratic.hess(x), A))\n",
    "    ok_(isinstance(quadratic.grad(x), np.ndarray))\n",
    "    ok_(isinstance(quadratic.hess(x), np.ndarray))\n",
    "\n",
    "    # Check at point x = [1, 1, 1]\n",
    "    x = np.ones(3)\n",
    "    assert_almost_equal(quadratic.func(x), -4.5)\n",
    "    ok_(np.allclose(quadratic.grad(x), x - b))\n",
    "    ok_(np.allclose(quadratic.hess(x), A))\n",
    "    ok_(isinstance(quadratic.grad(x), np.ndarray))\n",
    "    ok_(isinstance(quadratic.hess(x), np.ndarray))\n",
    "\n",
    "    # Check func_direction and grad_direction oracles at\n",
    "    # x = [1, 1, 1], d = [-1, -1, -1], alpha = 0.5 and 1.0\n",
    "    x = np.ones(3)\n",
    "    d = -np.ones(3)\n",
    "    assert_almost_equal(quadratic.func_directional(x, d, alpha=0.5),\n",
    "                        -2.625)\n",
    "    assert_almost_equal(quadratic.grad_directional(x, d, alpha=0.5),\n",
    "                        4.5)\n",
    "    assert_almost_equal(quadratic.func_directional(x, d, alpha=1.0),\n",
    "                        0.0)\n",
    "    assert_almost_equal(quadratic.grad_directional(x, d, alpha=1.0),\n",
    "                        6.0)\n",
    "\n",
    "\n",
    "def check_log_reg(oracle_type, sparse=False):\n",
    "    # Simple data:\n",
    "    A = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "    if sparse: A = scipy.sparse.csr_matrix(A)\n",
    "    b = np.array([1, 1, -1, 1])\n",
    "    reg_coef = 0.5\n",
    "\n",
    "    # Logistic regression oracle:\n",
    "    logreg = oracles.create_log_reg_oracle(A, b, reg_coef, oracle_type=oracle_type)\n",
    "\n",
    "    # Check at point x = [0, 0]\n",
    "    x = np.zeros(2)\n",
    "    assert_almost_equal(logreg.func(x), 0.693147180)\n",
    "    ok_(np.allclose(logreg.grad(x), [0, -0.25]))\n",
    "    ok_(np.allclose(logreg.hess(x), [[0.625, 0.0625], [0.0625, 0.625]]))\n",
    "    ok_(isinstance(logreg.grad(x), np.ndarray))\n",
    "    ok_(isinstance(logreg.hess(x), np.ndarray))\n",
    "\n",
    "    # Check func_direction and grad_direction oracles at\n",
    "    # x = [0, 0], d = [1, 1], alpha = 0.5 and 1.0\n",
    "    x = np.zeros(2)\n",
    "    d = np.ones(2)\n",
    "    assert_almost_equal(logreg.func_directional(x, d, alpha=0.5),\n",
    "                        0.7386407091095)\n",
    "    assert_almost_equal(logreg.grad_directional(x, d, alpha=0.5),\n",
    "                        0.4267589549159)\n",
    "    assert_almost_equal(logreg.func_directional(x, d, alpha=1.0),\n",
    "                        1.1116496416598)\n",
    "    assert_almost_equal(logreg.grad_directional(x, d, alpha=1.0),\n",
    "                        1.0559278283039)\n",
    "\n",
    "\n",
    "def test_log_reg_usual():\n",
    "    check_log_reg('usual')\n",
    "    check_log_reg('usual', sparse=True)\n",
    "\n",
    "\n",
    "@attr('bonus')\n",
    "def test_log_reg_optimized():\n",
    "    check_log_reg('optimized')\n",
    "    check_log_reg('optimized', sparse=True)\n",
    "\n",
    "\n",
    "def get_counters(A):\n",
    "    counters = {'Ax': 0, 'ATx': 0, 'ATsA': 0}\n",
    "\n",
    "    def matvec_Ax(x):\n",
    "        counters['Ax'] += 1\n",
    "        return A.dot(x)\n",
    "\n",
    "    def matvec_ATx(x):\n",
    "        counters['ATx'] += 1\n",
    "        return A.T.dot(x)\n",
    "\n",
    "    def matmat_ATsA(s):\n",
    "        counters['ATsA'] += 1\n",
    "        return A.T.dot(A * s.reshape(-1, 1))\n",
    "\n",
    "    return (matvec_Ax, matvec_ATx, matmat_ATsA, counters)\n",
    "\n",
    "\n",
    "def check_counters(counters, groundtruth):\n",
    "    for (key, value) in groundtruth.items():\n",
    "        ok_(key in counters)\n",
    "        ok_(counters[key] <= value)\n",
    "\n",
    "\n",
    "def test_log_reg_oracle_calls():\n",
    "\n",
    "    A = np.ones((2, 2))\n",
    "    b = np.ones(2)\n",
    "    x = np.ones(2)\n",
    "    d = np.ones(2)\n",
    "    reg_coef = 0.5\n",
    "\n",
    "    # Single func\n",
    "    (matvec_Ax, matvec_ATx, matmat_ATsA, counters) = get_counters(A)\n",
    "    oracles.LogRegL2Oracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, reg_coef).func(x)\n",
    "    check_counters(counters, {'Ax': 1, 'ATx': 0, 'ATsA': 0})\n",
    "\n",
    "    # Single grad\n",
    "    (matvec_Ax, matvec_ATx, matmat_ATsA, counters) = get_counters(A)\n",
    "    oracles.LogRegL2Oracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, reg_coef).grad(x)\n",
    "    check_counters(counters, {'Ax': 1, 'ATx': 1, 'ATsA': 0})\n",
    "\n",
    "    # Single hess\n",
    "    (matvec_Ax, matvec_ATx, matmat_ATsA, counters) = get_counters(A)\n",
    "    oracles.LogRegL2Oracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, reg_coef).hess(x)\n",
    "    check_counters(counters, {'Ax': 1, 'ATx': 0, 'ATsA': 1})\n",
    "\n",
    "    # Single func_directional\n",
    "    (matvec_Ax, matvec_ATx, matmat_ATsA, counters) = get_counters(A)\n",
    "    oracles.LogRegL2Oracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, reg_coef).func_directional(x, d, 1)\n",
    "    check_counters(counters, {'Ax': 1, 'ATx': 0, 'ATsA': 0})\n",
    "\n",
    "    # Single grad_directional\n",
    "    (matvec_Ax, matvec_ATx, matmat_ATsA, counters) = get_counters(A)\n",
    "    oracles.LogRegL2Oracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, reg_coef).grad_directional(x, d, 1)\n",
    "    check_counters(counters, {'Ax': 1, 'ATx': 1, 'ATsA': 0})\n",
    "\n",
    "    # In a row: func + grad + hess\n",
    "    (matvec_Ax, matvec_ATx, matmat_ATsA, counters) = get_counters(A)\n",
    "    oracle = oracles.LogRegL2Oracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, reg_coef)\n",
    "    oracle.func(x)\n",
    "    oracle.grad(x)\n",
    "    oracle.hess(x)\n",
    "    check_counters(counters, {'Ax': 3, 'ATx': 1, 'ATsA': 1})\n",
    "\n",
    "    # In a row: func + grad\n",
    "    (matvec_Ax, matvec_ATx, matmat_ATsA, counters) = get_counters(A)\n",
    "    oracle = oracles.LogRegL2Oracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, reg_coef)\n",
    "    oracle.func(x)\n",
    "    oracle.grad(x)\n",
    "    check_counters(counters, {'Ax': 2, 'ATx': 1, 'ATsA': 0})\n",
    "\n",
    "    # In a row: grad + hess\n",
    "    (matvec_Ax, matvec_ATx, matmat_ATsA, counters) = get_counters(A)\n",
    "    oracle = oracles.LogRegL2Oracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, reg_coef)\n",
    "    oracle.grad(x)\n",
    "    oracle.hess(x)\n",
    "    check_counters(counters, {'Ax': 2, 'ATx': 1, 'ATsA': 1})\n",
    "\n",
    "    # In a row: func + grad + func_directional + grad_directional\n",
    "    (matvec_Ax, matvec_ATx, matmat_ATsA, counters) = get_counters(A)\n",
    "    oracle = oracles.LogRegL2Oracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, reg_coef)\n",
    "    oracle.func(x)\n",
    "    oracle.grad(x)\n",
    "    oracle.func_directional(x, d, 1)\n",
    "    oracle.grad_directional(x, d, 2)\n",
    "    oracle.func_directional(x, d, 2)\n",
    "    oracle.func_directional(x, d, 3)\n",
    "    check_counters(counters, {'Ax': 6, 'ATx': 2, 'ATsA': 0})\n",
    "\n",
    "    # In a row: func + grad + func_directional + grad_directional + (func + grad)\n",
    "    (matvec_Ax, matvec_ATx, matmat_ATsA, counters) = get_counters(A)\n",
    "    oracle = oracles.LogRegL2Oracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, reg_coef)\n",
    "    oracle.func(x)\n",
    "    oracle.grad(x)\n",
    "    oracle.func_directional(x, d, 1)\n",
    "    oracle.grad_directional(x, d, 2)\n",
    "    oracle.func_directional(x, d, 2)\n",
    "    oracle.func_directional(x, d, 3)\n",
    "    oracle.func(x + 3 * d)\n",
    "    oracle.grad(x + 3 * d)\n",
    "    check_counters(counters, {'Ax': 8, 'ATx': 3, 'ATsA': 0})\n",
    "\n",
    "\n",
    "@attr('bonus')\n",
    "def test_log_reg_optimized_oracle_calls():\n",
    "\n",
    "    A = np.ones((2, 2))\n",
    "    b = np.ones(2)\n",
    "    x = np.ones(2)\n",
    "    d = np.ones(2)\n",
    "    reg_coef = 0.5\n",
    "\n",
    "    # Single func\n",
    "    (matvec_Ax, matvec_ATx, matmat_ATsA, counters) = get_counters(A)\n",
    "    oracles.LogRegL2OptimizedOracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, reg_coef).func(x)\n",
    "    check_counters(counters, {'Ax': 1, 'ATx': 0, 'ATsA': 0})\n",
    "\n",
    "    # Single grad\n",
    "    (matvec_Ax, matvec_ATx, matmat_ATsA, counters) = get_counters(A)\n",
    "    oracles.LogRegL2OptimizedOracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, reg_coef).grad(x)\n",
    "    check_counters(counters, {'Ax': 1, 'ATx': 1, 'ATsA': 0})\n",
    "\n",
    "    # Single hess\n",
    "    (matvec_Ax, matvec_ATx, matmat_ATsA, counters) = get_counters(A)\n",
    "    oracles.LogRegL2OptimizedOracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, reg_coef).hess(x)\n",
    "    check_counters(counters, {'Ax': 1, 'ATx': 0, 'ATsA': 1})\n",
    "\n",
    "    # Single func_directional\n",
    "    (matvec_Ax, matvec_ATx, matmat_ATsA, counters) = get_counters(A)\n",
    "    oracles.LogRegL2OptimizedOracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, reg_coef).func_directional(x, d, 1)\n",
    "    check_counters(counters, {'Ax': 2, 'ATx': 0, 'ATsA': 0})\n",
    "\n",
    "    # Single grad_directional\n",
    "    (matvec_Ax, matvec_ATx, matmat_ATsA, counters) = get_counters(A)\n",
    "    oracles.LogRegL2OptimizedOracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, reg_coef).grad_directional(x, d, 1)\n",
    "    check_counters(counters, {'Ax': 2, 'ATx': 0, 'ATsA': 0})\n",
    "\n",
    "    # In a row: func + grad + hess\n",
    "    (matvec_Ax, matvec_ATx, matmat_ATsA, counters) = get_counters(A)\n",
    "    oracle = oracles.LogRegL2OptimizedOracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, reg_coef)\n",
    "    oracle.func(x)\n",
    "    oracle.grad(x)\n",
    "    oracle.hess(x)\n",
    "    check_counters(counters, {'Ax': 1, 'ATx': 1, 'ATsA': 1})\n",
    "\n",
    "    # In a row: func + grad\n",
    "    (matvec_Ax, matvec_ATx, matmat_ATsA, counters) = get_counters(A)\n",
    "    oracle = oracles.LogRegL2OptimizedOracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, reg_coef)\n",
    "    oracle.func(x)\n",
    "    oracle.grad(x)\n",
    "    check_counters(counters, {'Ax': 1, 'ATx': 1, 'ATsA': 0})\n",
    "\n",
    "    # In a row: grad + hess\n",
    "    (matvec_Ax, matvec_ATx, matmat_ATsA, counters) = get_counters(A)\n",
    "    oracle = oracles.LogRegL2OptimizedOracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, reg_coef)\n",
    "    oracle.grad(x)\n",
    "    oracle.hess(x)\n",
    "    check_counters(counters, {'Ax': 1, 'ATx': 1, 'ATsA': 1})\n",
    "\n",
    "    # In a row: func + grad + func_directional + grad_directional\n",
    "    (matvec_Ax, matvec_ATx, matmat_ATsA, counters) = get_counters(A)\n",
    "    oracle = oracles.LogRegL2OptimizedOracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, reg_coef)\n",
    "    oracle.func(x)\n",
    "    oracle.grad(x)\n",
    "    oracle.func_directional(x, d, 1)\n",
    "    oracle.grad_directional(x, d, 2)\n",
    "    oracle.func_directional(x, d, 2)\n",
    "    oracle.func_directional(x, d, 3)\n",
    "    check_counters(counters, {'Ax': 2, 'ATx': 1, 'ATsA': 0})\n",
    "\n",
    "    # In a row: func + grad + func_directional + grad_directional + (func + grad)\n",
    "    (matvec_Ax, matvec_ATx, matmat_ATsA, counters) = get_counters(A)\n",
    "    oracle = oracles.LogRegL2OptimizedOracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, reg_coef)\n",
    "    oracle.func(x)\n",
    "    oracle.grad(x)\n",
    "    oracle.func_directional(x, d, 1)\n",
    "    oracle.grad_directional(x, d, 2)\n",
    "    oracle.func_directional(x, d, 2)\n",
    "    oracle.func_directional(x, d, 3)\n",
    "    oracle.func(x + 3 * d)\n",
    "    oracle.grad(x + 3 * d)\n",
    "    check_counters(counters, {'Ax': 2, 'ATx': 2, 'ATsA': 0})\n",
    "\n",
    "\n",
    "def test_grad_finite_diff_1():\n",
    "    # Quadratic function.\n",
    "    A = np.eye(3)\n",
    "    b = np.array([1, 2, 3])\n",
    "    quadratic = oracles.QuadraticOracle(A, b)\n",
    "    g = oracles.grad_finite_diff(quadratic.func, np.zeros(3))\n",
    "    ok_(isinstance(g, np.ndarray))\n",
    "    ok_(np.allclose(g, -b))\n",
    "\n",
    "\n",
    "def test_grad_finite_diff_2():\n",
    "    # f(x, y) = x^3 + y^2\n",
    "    func = lambda x: x[0] ** 3 + x[1] ** 2\n",
    "    x = np.array([2.0, 3.0])\n",
    "    eps = 1e-5\n",
    "    g = oracles.grad_finite_diff(func, x, eps)\n",
    "    ok_(isinstance(g, np.ndarray))\n",
    "    ok_(np.allclose(g, [12.0, 6.0], atol=1e-4))\n",
    "\n",
    "\n",
    "def test_hess_finite_diff_1():\n",
    "    # Quadratic function.\n",
    "    A = np.eye(3)\n",
    "    b = np.array([1, 2, 3])\n",
    "    quadratic = oracles.QuadraticOracle(A, b)\n",
    "    H = oracles.hess_finite_diff(quadratic.func, np.zeros(3))\n",
    "    ok_(isinstance(H, np.ndarray))\n",
    "    ok_(np.allclose(H, A))\n",
    "\n",
    "\n",
    "def test_hess_finite_diff_2():\n",
    "    # f(x, y) = x^3 + y^2\n",
    "    func = lambda x: x[0] ** 3 + x[1] ** 2\n",
    "    x = np.array([2.0, 3.0])\n",
    "    eps = 1e-5\n",
    "    H = oracles.hess_finite_diff(func, x, eps)\n",
    "    ok_(isinstance(H, np.ndarray))\n",
    "    ok_(np.allclose(H, [[12.0, 0.], [0., 2.0]], atol=1e-3))\n",
    "\n",
    "\n",
    "def get_quadratic():\n",
    "    # Quadratic function:\n",
    "    #   f(x) = 1/2 x^T x - [1, 2, 3]^T x\n",
    "    A = np.eye(3)\n",
    "    b = np.array([1, 2, 3])\n",
    "    return oracles.QuadraticOracle(A, b)\n",
    "\n",
    "\n",
    "def test_line_search():\n",
    "    oracle = get_quadratic()\n",
    "    x = np.array([100, 0, 0])\n",
    "    d = np.array([-1, 0, 0])\n",
    "\n",
    "    # Constant line search\n",
    "    ls_tool = optimization.LineSearchTool(method='Constant', c=1.0)\n",
    "    assert_almost_equal(ls_tool.line_search(oracle, x, d, ), 1.0)\n",
    "    ls_tool = optimization.LineSearchTool(method='Constant', c=10.0)\n",
    "    assert_almost_equal(ls_tool.line_search(oracle, x, d), 10.0)\n",
    "\n",
    "    # Armijo rule\n",
    "    ls_tool = optimization.LineSearchTool(method='Armijo', alpha_0=100, c1=0.9)\n",
    "    assert_almost_equal(ls_tool.line_search(oracle, x, d), 12.5)\n",
    "\n",
    "    ls_tool = optimization.LineSearchTool(method='Armijo', alpha_0=100, c1=0.9)\n",
    "    assert_almost_equal(ls_tool.line_search(oracle, x, d, previous_alpha=1.0), 1.0)\n",
    "\n",
    "    ls_tool = optimization.LineSearchTool(method='Armijo', alpha_0=100, c1=0.95)\n",
    "    assert_almost_equal(ls_tool.line_search(oracle, x, d), 6.25)\n",
    "    ls_tool = optimization.LineSearchTool(method='Armijo', alpha_0=10, c1=0.9)\n",
    "    assert_almost_equal(ls_tool.line_search(oracle, x, d), 10.0)\n",
    "\n",
    "    # Wolfe rule\n",
    "    ls_tool = optimization.LineSearchTool(method='Wolfe', c1=1e-4, c2=0.9)\n",
    "    assert_almost_equal(ls_tool.line_search(oracle, x, d), 16.0)\n",
    "    ls_tool = optimization.LineSearchTool(method='Wolfe', c1=1e-4, c2=0.8)\n",
    "    assert_almost_equal(ls_tool.line_search(oracle, x, d), 32.0)\n",
    "\n",
    "\n",
    "def check_equal_histories(history1, history2, atol=1e-3):\n",
    "    if history1 is None or history2 is None:\n",
    "        eq_(history1, history2)\n",
    "        return\n",
    "    ok_('func' in history1 and 'func' in history2)\n",
    "    ok_(np.allclose(history1['func'], history2['func'], atol=atol))\n",
    "    ok_('grad_norm' in history1 and 'grad_norm' in history2)\n",
    "    ok_(np.allclose(history1['grad_norm'], history2['grad_norm'], atol=atol))\n",
    "    ok_('time' in history1 and 'time' in history2)\n",
    "    eq_(len(history1['time']), len(history2['time']))\n",
    "    eq_('x' in history1, 'x' in history2)\n",
    "    if 'x' in history1:\n",
    "        ok_(np.allclose(history1['x'], history2['x'], atol=atol))\n",
    "\n",
    "\n",
    "def check_prototype(method):\n",
    "    class ZeroOracle2D(oracles.BaseSmoothOracle):\n",
    "        def func(self, x): return 0.0\n",
    "\n",
    "        def grad(self, x): return np.zeros(2)\n",
    "\n",
    "        def hess(self, x): return np.zeros([2, 2])\n",
    "\n",
    "    oracle = ZeroOracle2D()\n",
    "    x0 = np.ones(2)\n",
    "    HISTORY = {'func': [0.0],\n",
    "               'grad_norm': [0.0],\n",
    "               'time': [0],  # dummy timestamp\n",
    "               'x': [np.ones(2)]}\n",
    "\n",
    "    def check_result(result, x0=np.ones(2), msg='success', history=None):\n",
    "        eq_(len(result), 3)\n",
    "        ok_(np.allclose(result[0], x0))\n",
    "        eq_(result[1], msg)\n",
    "        check_equal_histories(result[2], history)\n",
    "\n",
    "    check_result(method(oracle, x0))\n",
    "    check_result(method(oracle, x0, 1e-3, 10))\n",
    "    check_result(method(oracle, x0, 1e-3, 10, {'method': 'Constant', 'c': 1.0}))\n",
    "    check_result(method(oracle, x0, 1e-3, 10, {'method': 'Constant', 'c': 1.0},\n",
    "                        trace=True), history=HISTORY)\n",
    "    check_result(method(oracle, x0, 1e-3, max_iter=10,\n",
    "                        line_search_options={'method': 'Constant', 'c': 1.0},\n",
    "                        trace=True, display=True), history=HISTORY)\n",
    "    check_result(method(oracle, x0, display=True, trace=False))\n",
    "    check_result(method(oracle, x0, tolerance=1e-8, trace=True),\n",
    "                 history=HISTORY)\n",
    "\n",
    "    # Check default display=False\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = mystdout = StringIO()\n",
    "    check_result(method(oracle, x0))\n",
    "    eq_(mystdout.getvalue(), \"\")\n",
    "    sys.stdout = old_stdout\n",
    "    # Check specified display=False\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = mystdout = StringIO()\n",
    "    check_result(method(oracle, x0, display=False))\n",
    "    eq_(mystdout.getvalue(), \"\")\n",
    "    sys.stdout = old_stdout\n",
    "    # Check specified display=True\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = mystdout = StringIO()\n",
    "    check_result(method(oracle, x0, display=True))\n",
    "    ok_(len(mystdout.getvalue()) > 1)\n",
    "    sys.stdout = old_stdout\n",
    "\n",
    "\n",
    "def check_one_ideal_step(method):\n",
    "    oracle = get_quadratic()\n",
    "    x0 = np.ones(3) * 10.0\n",
    "    [x_star, msg, history] = method(oracle, x0, max_iter=1,\n",
    "                                    tolerance=1e-5, trace=True)\n",
    "    ok_(np.allclose(x_star, [1.0, 2.0, 3.0]))\n",
    "    eq_(msg, 'success')\n",
    "    check_equal_histories(history, {'func': [90.0, -7.0],\n",
    "                                    'grad_norm': [13.928388277184119, 0.0],\n",
    "                                    'time': [0, 1]  # dummy timestamps\n",
    "                                    })\n",
    "\n",
    "\n",
    "def test_gd_basic():\n",
    "    check_prototype(optimization.gradient_descent)\n",
    "    check_one_ideal_step(optimization.gradient_descent)\n",
    "\n",
    "\n",
    "def test_newton_basic():\n",
    "    check_prototype(optimization.newton)\n",
    "    check_one_ideal_step(optimization.newton)\n",
    "\n",
    "\n",
    "def get_1d(alpha):\n",
    "    # 1D function:\n",
    "    #   f(x) = exp(alpha * x) + alpha * x^2\n",
    "    class Func(oracles.BaseSmoothOracle):\n",
    "        def __init__(self, alpha):\n",
    "            self.alpha = alpha\n",
    "\n",
    "        def func(self, x):\n",
    "            return np.exp(self.alpha * x) + self.alpha * x ** 2\n",
    "\n",
    "        def grad(self, x):\n",
    "            return np.array(self.alpha * np.exp(self.alpha * x) +\n",
    "                            2 * self.alpha * x)\n",
    "\n",
    "        def hess(self, x):\n",
    "            return np.array([self.alpha ** 2 * np.exp(self.alpha * x) +\n",
    "                             2 * self.alpha])\n",
    "\n",
    "    return Func(alpha)\n",
    "\n",
    "\n",
    "def test_gd_1d():\n",
    "    oracle = get_1d(0.5)\n",
    "    x0 = np.array([1.0])\n",
    "    FUNC = [\n",
    "        np.array([2.14872127]),\n",
    "        np.array([0.8988787]),\n",
    "        np.array([0.89869501]),\n",
    "        np.array([0.89869434]),\n",
    "        np.array([0.89869434])]\n",
    "    GRAD_NORM = [\n",
    "        1.8243606353500641,\n",
    "        0.021058536428132546,\n",
    "        0.0012677045924299746,\n",
    "        7.5436847232768223e-05,\n",
    "        4.485842052370792e-06]\n",
    "    TIME = [0] * 5  # Dummy values.\n",
    "    X = [\n",
    "        np.array([1.]),\n",
    "        np.array([-0.42528175]),\n",
    "        np.array([-0.40882976]),\n",
    "        np.array([-0.40783937]),\n",
    "        np.array([-0.40778044])]\n",
    "    TRUE_HISTORY = {'func': FUNC,\n",
    "                    'grad_norm': GRAD_NORM,\n",
    "                    'time': TIME,\n",
    "                    'x': X}\n",
    "    # Armijo rule.\n",
    "    [x_star, msg, history] = optimization.gradient_descent(\n",
    "        oracle, x0,\n",
    "        max_iter=5,\n",
    "        tolerance=1e-10,\n",
    "        trace=True,\n",
    "        line_search_options={\n",
    "            'method': 'Armijo',\n",
    "            'alpha_0': 100,\n",
    "            'c1': 0.3\n",
    "        }\n",
    "    )\n",
    "    ok_(np.allclose(x_star, [-0.4077], atol=1e-3))\n",
    "    eq_(msg, 'success')\n",
    "    check_equal_histories(history, TRUE_HISTORY)\n",
    "    # Constant step size.\n",
    "    [x_star, msg, history] = optimization.gradient_descent(oracle, x0,\n",
    "                                                           max_iter=5, tolerance=1e-10, trace=False,\n",
    "                                                           line_search_options={\n",
    "                                                               'method': 'Constant',\n",
    "                                                               'c': 1.0})\n",
    "    ok_(np.allclose(x_star, [-0.4084371], atol=1e-2))\n",
    "    eq_(msg, 'iterations_exceeded')\n",
    "    eq_(history, None)\n",
    "\n",
    "\n",
    "def test_newton_1d():\n",
    "    oracle = get_1d(0.5)\n",
    "    x0 = np.array([1.0])\n",
    "    FUNC = [\n",
    "        np.array([2.14872127]),\n",
    "        np.array([0.9068072]),\n",
    "        np.array([0.89869455]),\n",
    "        np.array([0.89869434])]\n",
    "    GRAD_NORM = [\n",
    "        1.8243606353500641,\n",
    "        0.14023069594489929,\n",
    "        0.00070465169721295462,\n",
    "        1.7464279966628027e-08]\n",
    "    TIME = [0] * 4  # Dummy values.\n",
    "    X = [\n",
    "        np.array([1.]),\n",
    "        np.array([-0.29187513]),\n",
    "        np.array([-0.40719141]),\n",
    "        np.array([-0.40777669])]\n",
    "    TRUE_HISTORY = {'func': FUNC,\n",
    "                    'grad_norm': GRAD_NORM,\n",
    "                    'time': TIME,\n",
    "                    'x': X}\n",
    "    # Constant step size.\n",
    "    [x_star, msg, history] = optimization.newton(\n",
    "        oracle, x0,\n",
    "        max_iter=5, tolerance=1e-10, trace=True,\n",
    "        line_search_options={\n",
    "            'method': 'Constant',\n",
    "            'c': 1.0}\n",
    "    )\n",
    "    ok_(np.allclose(x_star, [-0.4077777], atol=1e-4))\n",
    "    eq_(msg, 'success')\n",
    "    check_equal_histories(history, TRUE_HISTORY)\n",
    "\n",
    "\n",
    "def test_newton_fail():\n",
    "    # f(x) = integral_{-infty}^x arctan(t) dt\n",
    "    class Oracle(oracles.BaseSmoothOracle):\n",
    "        def func(self, x):\n",
    "            return x * np.arctan(x) - 0.5 * np.log(np.power(x, 2) + 1)\n",
    "\n",
    "        def grad(self, x):\n",
    "            return np.arctan(x)\n",
    "\n",
    "        def hess(self, x):\n",
    "            return np.array([1 / (np.power(x, 2) + 1)])\n",
    "\n",
    "    x0 = np.array([10.0])\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    [x_star, msg, history] = optimization.newton(Oracle(), x0,\n",
    "                                                 display=False, trace=False,\n",
    "                                                 line_search_options={'method': 'Constant', 'c': 1})\n",
    "    warnings.filterwarnings(\"default\")\n",
    "    eq_(msg, 'computational_error')\n",
    "    eq_(history, None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07380bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
